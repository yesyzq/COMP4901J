{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Recurrent Q-Network \n",
    "This notebook provides an example implementation of a Deep Recurrent Q-Network which can solve Partially Observable Markov Decision Processes. To learn more about DRQNs, see my blog post on them here: https://medium.com/p/68463e9aeefc .\n",
    "\n",
    "For more reinforcment learning tutorials, as well as the additional required `gridworld.py` and `helper.py` see:\n",
    "https://github.com/awjuliani/DeepRL-Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "import csv\n",
    "import itertools\n",
    "import tensorflow.contrib.slim as slim\n",
    "%matplotlib inline\n",
    "\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the game environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gridworld import gameEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to adjust the size of the gridworld. Making it smaller (adjusting `size`) provides an easier task for our DRQN agent, while making the world larger increases the challenge.\n",
    "\n",
    "Initializing the Gridworld with `True` limits the field of view, resulting in a partially observable MDP. Initializing it with `False` provides the agent with the entire environment, resulting in a fully MDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADNZJREFUeJzt3V+sHOV5x/HvrzaEQIqM+ScXQw0S\nIqBKGGpRKFXVQtxSGkEvkgoUVVGFxE3aQhMpgfYiitQLIlUJuagiIUiKKsqfEGgsKyK1HKKqUuVg\n/jQBDMEQF1wINimUNJHaOnl6seP2yD3Gc3xm9+zwfj/Sanfe3T3zjke/M7N7xs+TqkJSW35upScg\nafYMvtQggy81yOBLDTL4UoMMvtQggy81aFnBT3JVkueT7E5yy1CTkjRdOdoLeJKsAr4HbAb2Ao8B\n11fVs8NNT9I0rF7Gey8BdlfVSwBJ7gOuBQ4b/FNOOaU2bNiwjFVKeid79uzhjTfeyJFet5zgnwG8\nsmB5L/Ar7/SGDRs2sHPnzmWsUtI72bRpU6/XLecz/mK/Vf7f54YkNybZmWTn/v37l7E6SUNZTvD3\nAmcuWF4PvHroi6rqjqraVFWbTj311GWsTtJQlhP8x4Bzk5yd5FjgOmDLMNOSNE1H/Rm/qg4k+SPg\nG8Aq4EtV9cxgM5M0Ncv5co+q+jrw9YHmImlGvHJPapDBlxpk8KUGGXypQQZfapDBlxpk8KUGGXyp\nQQZfapDBlxpk8KUGGXypQQZfapDBlxq0rP+WOw+SI9YVlObWSrWp94gvNcjgSw06YvCTfCnJviRP\nLxhbm2Rbkhe6+5OmO01JQ+pzxP9r4KpDxm4BtlfVucD2blnSSBwx+FX1D8C/HTJ8LXB39/hu4PcG\nnpekKTraz/inV9VrAN39acNNSdK0Tf3LPTvpSPPnaIP/epJ1AN39vsO90E460vw52uBvAT7aPf4o\n8LVhpiNpFvr8Oe9e4J+A85LsTXIDcBuwOckLwOZuWdJIHPGS3aq6/jBPXTnwXCTNiFfuSQ0y+FKD\nDL7UIIMvNcjgSw0y+FKDRl+BZ54NXVvFWkMaikd8qUEGX2qQwZcaZPClBhl8qUEGX2qQwZcaZPCl\nBhl8qUEGX2pQn9JbZyZ5NMmuJM8kuakbt5uONFJ9jvgHgE9U1fnApcDHklyA3XSk0erTSee1qnqi\ne/wjYBdwBnbTkUZrSZ/xk2wALgJ20LObjg01pPnTO/hJ3gd8Fbi5qt7u+z4bakjzp1fwkxzDJPT3\nVNVD3XDvbjqS5kufb/UD3AXsqqrPLXjKbjrSSPWpwHM58AfAd5M81Y39GZPuOQ90nXVeBj48nSlK\nGlqfTjr/yOGrPtlNRxohr9yTGmSxzSmK1TY1pzziSw0y+FKDDL7UIIMvNcjgSw0y+FKDDL7UIIMv\nNcjgSw0y+FKDDL7UIIMvNcjgSw0y+FKDDL7UoD41945L8u0k/9x10vlMN352kh1dJ537kxw7/elK\nGkKfI/5/AldU1YXARuCqJJcCnwU+33XSeRO4YXrTlDSkPp10qqr+o1s8prsVcAXwYDduJx1pRPrW\n1V/VVdjdB2wDXgTeqqoD3Uv2Mmmrtdh77aQjzZlewa+qn1bVRmA9cAlw/mIvO8x72+2kk4Fv0kCW\n9K1+Vb0FfItJ19w1SQ4W61wPvDrs1CRNS59v9U9NsqZ7/F7gA0w65j4KfKh7mZ10pBHpU157HXB3\nklVMflE8UFVbkzwL3JfkL4AnmbTZkjQCfTrpfIdJa+xDx19i8nlf0sh45Z7UIIMvNcjgSw0y+FKD\nDL7UIIMvNcjgSw0y+FKDDL7UIIMvNcjgSw0y+FKDDL7UIIMvNcjgSw0y+FKDDL7UoN7B70psP5lk\na7dsJx1ppJZyxL+JSZHNg+ykI41U34Ya64HfBe7sloOddKTR6nvEvx34JPCzbvlk7KQjjVafuvof\nBPZV1eMLhxd5qZ10pJHoU1f/cuCaJFcDxwEnMjkDWJNkdXfUt5OONCJ9uuXeWlXrq2oDcB3wzar6\nCHbSkUZrOX/H/xTw8SS7mXzmt5OONBJ9TvX/V1V9i0nTTDvpSCPmlXtSgwy+1CCDLzXI4EsNMvhS\ngwy+1CCDLzXI4EsNMvhSgwy+1CCDLzXI4EsNMvhSgwy+1CCDLzXI4EsN6lWII8ke4EfAT4EDVbUp\nyVrgfmADsAf4/ap6czrTlDSkpRzxf7OqNlbVpm75FmB711Bje7csaQSWc6p/LZNGGmBDDWlU+ga/\ngL9P8niSG7ux06vqNYDu/rRpTFDS8PoW27y8ql5NchqwLclzfVfQ/aK4EeCss846iilKGlqvI35V\nvdrd7wMeZlJd9/Uk6wC6+32Hea+ddKQ506eF1glJfv7gY+C3gKeBLUwaaYANNaRR6XOqfzrw8KRB\nLquBv62qR5I8BjyQ5AbgZeDD05umpCEdMfhd44wLFxn/IXDlNCYlabq8ck9qkMGXGrSk3nl6N6mB\nf14G/nlzbuh/vhnziC81yOBLDTL4UoMMvtQggy81yOBLDTL4UoMMvtQggy81yOBLDTL4UoMMvtQg\ngy81yOBLDeoV/CRrkjyY5Lkku5JclmRtkm1JXujuT5r2ZCUNo+8R/wvAI1X1fiZluHZhJx1ptPpU\n2T0R+HXgLoCq+q+qegs76Uij1eeIfw6wH/hykieT3NmV2baTjjRSfYK/GrgY+GJVXQT8mCWc1ie5\nMcnOJDv3799/lNOUNKQ+wd8L7K2qHd3yg0x+EdhJZ9ZqwBsZ+NaYkf+zHTH4VfUD4JUk53VDVwLP\nYicdabT6Vtn9Y+CeJMcCLwF/yOSXhp10pBHqFfyqegrYtMhTdtKRRsgr96QGGXypQQZfapDBlxpk\n8KUGGXypQQZfapDBlxpk8KUGGXypQQZfapDBlxpk8KUGGXypQQZfapDBlxpk8KUG9amrf16Spxbc\n3k5y87uuk86QhSy729A/0tqYGkqfYpvPV9XGqtoI/DLwE+Bh7KQjjdZST/WvBF6sqn/BTjrSaC01\n+NcB93aP7aQjjVTv4Helta8BvrKUFdhJR5o/Szni/w7wRFW93i3bSUcaqaUE/3r+7zQf7KQjjVav\n4Cc5HtgMPLRg+DZgc5IXuuduG356kqahbyednwAnHzL2Q+ykI42SV+5JDTL4UoMMvtQggy81yOBL\nDTL4UoMMvtQggy81yOBLDep15d48q6qVnsLhDTy1Od5SjYxHfKlBBl9qkMGXGmTwpQYZfKlBBl9q\nkMGXGtS39NafJnkmydNJ7k1yXJKzk+zoOunc31XhlTQCfVponQH8CbCpqn4JWMWkvv5ngc93nXTe\nBG6Y5kQlDafvqf5q4L1JVgPHA68BVwAPds/bSUcakT698/4V+EvgZSaB/3fgceCtqjrQvWwvcMa0\nJilpWH1O9U9i0ifvbOAXgBOYNNc41KKXkttJR5o/fU71PwB8v6r2V9V/M6mt/6vAmu7UH2A98Opi\nb7aTjjR/+gT/ZeDSJMcnCZNa+s8CjwIf6l5jJx1pRPp8xt/B5Eu8J4Dvdu+5A/gU8PEku5k027hr\nivOUNKC+nXQ+DXz6kOGXgEsGn5GkqfPKPalBBl9qkMGXGmTwpQZllsUqk+wHfgy8MbOVTt8puD3z\n6t20LdBve36xqo54wcxMgw+QZGdVbZrpSqfI7Zlf76ZtgWG3x1N9qUEGX2rQSgT/jhVY5zS5PfPr\n3bQtMOD2zPwzvqSV56m+1KCZBj/JVUmeT7I7yS2zXPdyJTkzyaNJdnX1B2/qxtcm2dbVHtzW1S8Y\njSSrkjyZZGu3PNpaiknWJHkwyXPdfrpszPtnmrUuZxb8JKuAv2JSxOMC4PokF8xq/QM4AHyiqs4H\nLgU+1s3/FmB7V3twe7c8JjcBuxYsj7mW4heAR6rq/cCFTLZrlPtn6rUuq2omN+Ay4BsLlm8Fbp3V\n+qewPV8DNgPPA+u6sXXA8ys9tyVsw3omYbgC2AqEyQUiqxfbZ/N8A04Evk/3vdWC8VHuHyal7F4B\n1jL5X7Rbgd8eav/M8lT/4IYcNNo6fUk2ABcBO4DTq+o1gO7+tJWb2ZLdDnwS+Fm3fDLjraV4DrAf\n+HL30eXOJCcw0v1TU651OcvgZ5Gx0f1JIcn7gK8CN1fV2ys9n6OV5IPAvqp6fOHwIi8dyz5aDVwM\nfLGqLmJyafgoTusXs9xal0cyy+DvBc5csHzYOn3zKskxTEJ/T1U91A2/nmRd9/w6YN9KzW+JLgeu\nSbIHuI/J6f7t9KylOIf2AntrUjEKJlWjLma8+2dZtS6PZJbBfww4t/tW8lgmX1RsmeH6l6WrN3gX\nsKuqPrfgqS1Mag7CiGoPVtWtVbW+qjYw2RffrKqPMNJailX1A+CVJOd1QwdrQ45y/zDtWpcz/sLi\nauB7wIvAn6/0FyhLnPuvMTmt+g7wVHe7msnn4u3AC9392pWe61Fs228AW7vH5wDfBnYDXwHes9Lz\nW8J2bAR2dvvo74CTxrx/gM8AzwFPA38DvGeo/eOVe1KDvHJPapDBlxpk8KUGGXypQQZfapDBlxpk\n8KUGGXypQf8DKyEezafu75kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c6ee1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gameEnv(partial=False,size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIIMvNcjgSw0y+FKDDL7UIIMvNei/AUr03P/6YSGjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117959e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gameEnv(partial=True,size=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above are examples of a starting environment in our simple game. The agent controls the blue square, and can move up, down, left, or right. The goal is to move to the green squares (for +1 reward) and avoid the red squares (for -1 reward). When the agent moves through a green or red square, it is randomly moved to a new place in the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the network itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self,h_size,rnn_cell,myScope):\n",
    "        #The network recieves a frame from the game, flattened into an array.\n",
    "        #It then resizes it and processes it through four convolutional layers.\n",
    "        self.scalarInput =  tf.placeholder(shape=[None,21168],dtype=tf.float32)\n",
    "        self.imageIn = tf.reshape(self.scalarInput,shape=[-1,84,84,3])\n",
    "        self.conv1 = slim.convolution2d( \\\n",
    "            inputs=self.imageIn,num_outputs=32,\\\n",
    "            kernel_size=[8,8],stride=[4,4],padding='VALID', \\\n",
    "            biases_initializer=None,scope=myScope+'_conv1')\n",
    "        self.conv2 = slim.convolution2d( \\\n",
    "            inputs=self.conv1,num_outputs=64,\\\n",
    "            kernel_size=[4,4],stride=[2,2],padding='VALID', \\\n",
    "            biases_initializer=None,scope=myScope+'_conv2')\n",
    "        self.conv3 = slim.convolution2d( \\\n",
    "            inputs=self.conv2,num_outputs=64,\\\n",
    "            kernel_size=[3,3],stride=[1,1],padding='VALID', \\\n",
    "            biases_initializer=None,scope=myScope+'_conv3')\n",
    "        self.conv4 = slim.convolution2d( \\\n",
    "            inputs=self.conv3,num_outputs=h_size,\\\n",
    "            kernel_size=[7,7],stride=[1,1],padding='VALID', \\\n",
    "            biases_initializer=None,scope=myScope+'_conv4')\n",
    "        \n",
    "        self.trainLength = tf.placeholder(dtype=tf.int32)\n",
    "        #We take the output from the final convolutional layer and send it to a recurrent layer.\n",
    "        #The input must be reshaped into [batch x trace x units] for rnn processing, \n",
    "        #and then returned to [batch x units] when sent through the upper levles.\n",
    "        self.batch_size = tf.placeholder(dtype=tf.int32,shape=[])\n",
    "        self.convFlat = tf.reshape(slim.flatten(self.conv4),[self.batch_size,self.trainLength,h_size])\n",
    "        self.state_in = rnn_cell.zero_state(self.batch_size, tf.float32)\n",
    "        self.rnn,self.rnn_state = tf.nn.dynamic_rnn(\\\n",
    "                inputs=self.convFlat,cell=rnn_cell,dtype=tf.float32,initial_state=self.state_in,scope=myScope+'_rnn')\n",
    "        self.rnn = tf.reshape(self.rnn,shape=[-1,h_size])\n",
    "        #The output from the recurrent player is then split into separate Value and Advantage streams\n",
    "        self.streamA,self.streamV = tf.split(self.rnn,2,1)\n",
    "        self.AW = tf.Variable(tf.random_normal([h_size//2,4]))\n",
    "        self.VW = tf.Variable(tf.random_normal([h_size//2,1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,self.AW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        \n",
    "        self.salience = tf.gradients(self.Advantage,self.imageIn)\n",
    "        #Then combine them together to get our final Q-values.\n",
    "        self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,4,dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis=1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        \n",
    "        #In order to only propogate accurate gradients through the network, we will mask the first\n",
    "        #half of the losses for each trace as per Lample & Chatlot 2016\n",
    "        self.maskA = tf.zeros([self.batch_size,self.trainLength//2])\n",
    "        self.maskB = tf.ones([self.batch_size,self.trainLength//2])\n",
    "        self.mask = tf.concat([self.maskA,self.maskB],1)\n",
    "        self.mask = tf.reshape(self.mask,[-1])\n",
    "        self.loss = tf.reduce_mean(self.td_error * self.mask)\n",
    "        \n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience Replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These classes allow us to store experies and sample then randomly to train the network.\n",
    "Episode buffer stores experiences for each individal episode.\n",
    "Experience buffer stores entire episodes of experience, and sample() allows us to get training batches needed from the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 1000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        if len(self.buffer) + 1 >= self.buffer_size:\n",
    "            self.buffer[0:(1+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self,batch_size,trace_length):\n",
    "        sampled_episodes = random.sample(self.buffer,batch_size)\n",
    "        sampledTraces = []\n",
    "        for episode in sampled_episodes:\n",
    "            point = np.random.randint(0,len(episode)+1-trace_length)\n",
    "            sampledTraces.append(episode[point:point+trace_length])\n",
    "        sampledTraces = np.array(sampledTraces)\n",
    "        return np.reshape(sampledTraces,[batch_size*trace_length,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setting the training parameters\n",
    "batch_size = 4 #How many experience traces to use for each training step.\n",
    "trace_length = 8 #How long each experience trace will be when training\n",
    "update_freq = 5 #How often to perform a training step.\n",
    "y = .99 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "anneling_steps = 10000 #How many steps of training to reduce startE to endE.\n",
    "num_episodes = 10000 #How many episodes of game environment to train network with.\n",
    "pre_train_steps = 10000 #How many steps of random actions before training begins.\n",
    "load_model = False #Whether to load a saved model.\n",
    "path = \"./drqn\" #The path to save our model to.\n",
    "h_size = 512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "max_epLength = 50 #The max allowed length of our episode.\n",
    "time_per_step = 1 #Length of each step used in gif creation\n",
    "summaryLength = 100 #Number of epidoes to periodically save for analysis\n",
    "tau = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Set Success\n",
      "Episode 9 reward: 0.8\n",
      "Episode 19 reward: 0.4\n",
      "Episode 29 reward: 0.9\n",
      "Episode 39 reward: 0.2\n",
      "Episode 49 reward: 1.2\n",
      "Episode 59 reward: 1.2\n",
      "Episode 69 reward: 1.0\n",
      "Episode 79 reward: 0.1\n",
      "Episode 89 reward: 0.5\n",
      "Episode 99 reward: 0.1\n",
      "Episode 109 reward: 0.0\n",
      "Episode 119 reward: -0.3\n",
      "Episode 129 reward: 0.2\n",
      "Episode 139 reward: 0.7\n",
      "Episode 149 reward: 0.1\n",
      "Episode 159 reward: 0.0\n",
      "Episode 169 reward: 0.2\n",
      "Episode 179 reward: 0.6\n",
      "Episode 189 reward: 0.7\n",
      "Episode 199 reward: 1.2\n",
      "Target Set Success\n",
      "Target Set Success\n",
      "Target Set Success\n",
      "Target Set Success\n",
      "Target Set Success\n",
      "Target Set Success\n",
      "Target Set Success\n",
      "Target Set Success\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e207c884a0fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mtargetQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainBatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdoubleQ\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mend_multiplier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0;31m#Update the network with our target values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmainQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdateModel\u001b[0m\u001b[0;34m,\u001b[0m                         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmainQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalarInput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainBatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmainQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargetQ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtargetQ\u001b[0m\u001b[0;34m,\u001b[0m                        \u001b[0mmainQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrainBatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmainQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainLength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrace_length\u001b[0m\u001b[0;34m,\u001b[0m                        \u001b[0mmainQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_in\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstate_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmainQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mrAll\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "#We define the cells for the primary and target q-networks\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=h_size,state_is_tuple=True)\n",
    "cellT = tf.contrib.rnn.BasicLSTMCell(num_units=h_size,state_is_tuple=True)\n",
    "mainQN = Qnetwork(h_size,cell,'main')\n",
    "targetQN = Qnetwork(h_size,cellT,'target')\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=5)\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "targetOps = updateTargetGraph(trainables,tau)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#Set the rate of random action decrease. \n",
    "e = startE\n",
    "stepDrop = (startE - endE)/anneling_steps\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "total_steps = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "##Write the first line of the master log-file for the Control Center\n",
    "# with open('./Center/log.csv', 'w') as myfile:\n",
    "#     wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "#     wr.writerow(['Episode','Length','Reward','IMG','LOG','SAL'])    \n",
    "  \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if load_model == True:\n",
    "        print ('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    sess.run(init)\n",
    "   \n",
    "    updateTarget(targetOps,sess) #Set the target network to be equal to the primary network.\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = []\n",
    "        #Reset environment and get first new observation\n",
    "        sP = env.reset()\n",
    "        s = processState(sP)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        state = (np.zeros([1,h_size]),np.zeros([1,h_size])) #Reset the recurrent layer's hidden state\n",
    "        #The Q-Network\n",
    "        while j < max_epLength: \n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                state1 = sess.run(mainQN.rnn_state,\\\n",
    "                    feed_dict={mainQN.scalarInput:[s/255.0],mainQN.trainLength:1,mainQN.state_in:state,mainQN.batch_size:1})\n",
    "                a = np.random.randint(0,4)\n",
    "            else:\n",
    "                a, state1 = sess.run([mainQN.predict,mainQN.rnn_state],\\\n",
    "                    feed_dict={mainQN.scalarInput:[s/255.0],mainQN.trainLength:1,mainQN.state_in:state,mainQN.batch_size:1})\n",
    "                a = a[0]\n",
    "            s1P,r,d = env.step(a)\n",
    "            s1 = processState(s1P)\n",
    "            total_steps += 1\n",
    "            episodeBuffer.append(np.reshape(np.array([s,a,r,s1,d]),[1,5]))\n",
    "            if total_steps > pre_train_steps:\n",
    "                if e > endE:\n",
    "                    e -= stepDrop\n",
    "\n",
    "                if total_steps % (update_freq) == 0:\n",
    "                    updateTarget(targetOps,sess)\n",
    "                    #Reset the recurrent layer's hidden state\n",
    "                    state_train = (np.zeros([batch_size,h_size]),np.zeros([batch_size,h_size])) \n",
    "                    \n",
    "                    trainBatch = myBuffer.sample(batch_size,trace_length) #Get a random batch of experiences.\n",
    "                    #Below we perform the Double-DQN update to the target Q-values\n",
    "                    Q1 = sess.run(mainQN.predict,feed_dict={\\\n",
    "                        mainQN.scalarInput:np.vstack(trainBatch[:,3]/255.0),\\\n",
    "                        mainQN.trainLength:trace_length,mainQN.state_in:state_train,mainQN.batch_size:batch_size})\n",
    "                    Q2 = sess.run(targetQN.Qout,feed_dict={\\\n",
    "                        targetQN.scalarInput:np.vstack(trainBatch[:,3]/255.0),\\\n",
    "                        targetQN.trainLength:trace_length,targetQN.state_in:state_train,targetQN.batch_size:batch_size})\n",
    "                    end_multiplier = -(trainBatch[:,4] - 1)\n",
    "                    doubleQ = Q2[range(batch_size*trace_length),Q1]\n",
    "                    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n",
    "                    #Update the network with our target values.\n",
    "                    sess.run(mainQN.updateModel, \\\n",
    "                        feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]/255.0),mainQN.targetQ:targetQ,\\\n",
    "                        mainQN.actions:trainBatch[:,1],mainQN.trainLength:trace_length,\\\n",
    "                        mainQN.state_in:state_train,mainQN.batch_size:batch_size})\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            sP = s1P\n",
    "            state = state1\n",
    "            if d == True:\n",
    "\n",
    "                break\n",
    "\n",
    "        #Add the episode to the experience buffer\n",
    "        bufferArray = np.array(episodeBuffer)\n",
    "        episodeBuffer = list(zip(bufferArray))\n",
    "        myBuffer.add(episodeBuffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "\n",
    "        #Periodically save the model. \n",
    "        if i % 1000 == 0 and i != 0:\n",
    "            saver.save(sess,path+'/model-'+str(i)+'.cptk')\n",
    "            print (\"Saved Model\")\n",
    "        if len(rList) % 10 == 0:\n",
    "            print(\"Episode\",i,\"reward:\",np.mean(rList[-10:]))\n",
    "    saver.save(sess,path+'/model-'+str(i)+'.cptk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Testing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a3160e1d0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a31595a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rMat = np.resize(np.array(rList),[len(rList)//100,100])\n",
    "rMean = np.average(rMat,1)\n",
    "plt.plot(rMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
